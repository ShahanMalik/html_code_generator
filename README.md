# HTML Code Generator with Attention Mechanism

This project implements a **sequence-to-sequence model** with a custom **attention mechanism** to generate HTML code from natural language descriptions.

## ðŸš€ Features
- **Bidirectional LSTM Encoder**: Captures both forward and backward dependencies.
- **Attention Layer**: Helps the model focus on relevant parts of the input sequence.
- **Beam Search**: Improves the quality of generated HTML.
- **Customizable Vocabulary**: Supports up to 15,000 unique tokens, including `<start>` and `<end>`.

## Demo
-

![Screenshot](https://github.com/user-attachments/assets/9f9ac2ac-ddd2-4a56-9cb9-cfb77ac21c13)



