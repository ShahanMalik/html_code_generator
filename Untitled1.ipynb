{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOc8baasTOyyHL6/gWHzqHF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShahanMalik/html_code_generator/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeXpJoZaB1vO",
        "outputId": "cf8c2271-594a-4f3c-8c4e-5c7479fbf91a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMIY2iATB1rx",
        "outputId": "830d74da-f5c5-4acf-f906-af731f445956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow numpy scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjxbBLOKB1pi",
        "outputId": "5ce167f3-d72b-49e9-bcc8-8afd742368db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x0mz21lrh-p2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea8fca9-eb2a-446a-df7c-f7590eb80fd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.0274 - loss: 4.4901 - val_accuracy: 0.0227 - val_loss: 4.4883\n",
            "Epoch 2/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0726 - loss: 4.4722 - val_accuracy: 0.0000e+00 - val_loss: 4.4947\n",
            "Epoch 3/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1126 - loss: 4.4537 - val_accuracy: 0.0000e+00 - val_loss: 4.5008\n",
            "Epoch 4/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1789 - loss: 4.4253 - val_accuracy: 0.0000e+00 - val_loss: 4.5142\n",
            "Epoch 5/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1635 - loss: 4.3981 - val_accuracy: 0.0000e+00 - val_loss: 4.5342\n",
            "Epoch 6/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1371 - loss: 4.3562 - val_accuracy: 0.0000e+00 - val_loss: 4.5652\n",
            "Epoch 7/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1396 - loss: 4.2930 - val_accuracy: 0.0000e+00 - val_loss: 4.6059\n",
            "Epoch 8/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1866 - loss: 4.2300 - val_accuracy: 0.0000e+00 - val_loss: 4.6594\n",
            "Epoch 9/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1946 - loss: 4.1623 - val_accuracy: 0.0000e+00 - val_loss: 4.7320\n",
            "Epoch 10/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2107 - loss: 4.0307 - val_accuracy: 0.0000e+00 - val_loss: 4.8264\n",
            "Epoch 11/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2300 - loss: 3.9284 - val_accuracy: 0.0000e+00 - val_loss: 4.9143\n",
            "Epoch 12/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2360 - loss: 3.8342 - val_accuracy: 0.0000e+00 - val_loss: 4.9841\n",
            "Epoch 13/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2835 - loss: 3.6634 - val_accuracy: 0.0000e+00 - val_loss: 5.0621\n",
            "Epoch 14/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2319 - loss: 3.5279 - val_accuracy: 0.0000e+00 - val_loss: 5.1521\n",
            "Epoch 15/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2818 - loss: 3.4361 - val_accuracy: 0.0000e+00 - val_loss: 5.2093\n",
            "Epoch 16/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3169 - loss: 3.2918 - val_accuracy: 0.0000e+00 - val_loss: 5.3025\n",
            "Epoch 17/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4228 - loss: 3.0502 - val_accuracy: 0.0000e+00 - val_loss: 5.3807\n",
            "Epoch 18/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4944 - loss: 2.8494 - val_accuracy: 0.0000e+00 - val_loss: 5.4786\n",
            "Epoch 19/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5280 - loss: 2.6995 - val_accuracy: 0.0000e+00 - val_loss: 5.4889\n",
            "Epoch 20/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5993 - loss: 2.5157 - val_accuracy: 0.0455 - val_loss: 5.5552\n",
            "Epoch 21/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6545 - loss: 2.2662 - val_accuracy: 0.0455 - val_loss: 5.6353\n",
            "Epoch 22/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7025 - loss: 2.0573 - val_accuracy: 0.0682 - val_loss: 5.7263\n",
            "Epoch 23/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7528 - loss: 1.9461 - val_accuracy: 0.0682 - val_loss: 5.7571\n",
            "Epoch 24/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7986 - loss: 1.8120 - val_accuracy: 0.0682 - val_loss: 5.8172\n",
            "Epoch 25/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8334 - loss: 1.5647 - val_accuracy: 0.0682 - val_loss: 5.9004\n",
            "Epoch 26/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8604 - loss: 1.4206 - val_accuracy: 0.0682 - val_loss: 6.0026\n",
            "Epoch 27/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8982 - loss: 1.2487 - val_accuracy: 0.0909 - val_loss: 6.0696\n",
            "Epoch 28/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9578 - loss: 1.1253 - val_accuracy: 0.0909 - val_loss: 6.1455\n",
            "Epoch 29/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9359 - loss: 1.0734 - val_accuracy: 0.1136 - val_loss: 6.2583\n",
            "Epoch 30/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9405 - loss: 0.9348 - val_accuracy: 0.0909 - val_loss: 6.3808\n",
            "Epoch 31/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9514 - loss: 0.8452 - val_accuracy: 0.0909 - val_loss: 6.4532\n",
            "Epoch 32/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9705 - loss: 0.7812 - val_accuracy: 0.1136 - val_loss: 6.5653\n",
            "Epoch 33/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9750 - loss: 0.6853 - val_accuracy: 0.0909 - val_loss: 6.6334\n",
            "Epoch 34/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9753 - loss: 0.6395 - val_accuracy: 0.0909 - val_loss: 6.7108\n",
            "Epoch 35/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9697 - loss: 0.5374 - val_accuracy: 0.0909 - val_loss: 6.8222\n",
            "Epoch 36/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9853 - loss: 0.4672 - val_accuracy: 0.0909 - val_loss: 6.8964\n",
            "Epoch 37/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9869 - loss: 0.4457 - val_accuracy: 0.0909 - val_loss: 7.0128\n",
            "Epoch 38/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9975 - loss: 0.4413 - val_accuracy: 0.0909 - val_loss: 7.0715\n",
            "Epoch 39/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.4118 - val_accuracy: 0.0909 - val_loss: 7.1774\n",
            "Epoch 40/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.3671 - val_accuracy: 0.0909 - val_loss: 7.2418\n",
            "Epoch 41/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9890 - loss: 0.3468 - val_accuracy: 0.0909 - val_loss: 7.3321\n",
            "Epoch 42/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9947 - loss: 0.3038 - val_accuracy: 0.0909 - val_loss: 7.3823\n",
            "Epoch 43/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.2906 - val_accuracy: 0.0909 - val_loss: 7.4705\n",
            "Epoch 44/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9946 - loss: 0.2492 - val_accuracy: 0.0909 - val_loss: 7.5453\n",
            "Epoch 45/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.2346 - val_accuracy: 0.0909 - val_loss: 7.6331\n",
            "Epoch 46/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.2463 - val_accuracy: 0.0909 - val_loss: 7.7015\n",
            "Epoch 47/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.2176 - val_accuracy: 0.0909 - val_loss: 7.7573\n",
            "Epoch 48/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9918 - loss: 0.1899 - val_accuracy: 0.0909 - val_loss: 7.8229\n",
            "Epoch 49/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9946 - loss: 0.1716 - val_accuracy: 0.0909 - val_loss: 7.8741\n",
            "Epoch 50/50\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 0.1539 - val_accuracy: 0.0909 - val_loss: 7.9188\n",
            "Test Accuracy: 0.1091\n",
            "Enter your HTML code generation request (or 'exit' to quit): Generate a paragraph and Create a list\n",
            "\n",
            "<!DOCTYPE html>\n",
            "<html>\n",
            "<head>\n",
            "<title>Html generator</title>\n",
            "</head>\n",
            "<body>\n",
            "<p>This is a paragraph of text.</p>\n",
            "<ul>\n",
            "  <li>Item 1</li>\n",
            "  <li>Item 2</li>\n",
            "  <li>Item 3</li>\n",
            "</ul>\n",
            "</body>\n",
            "</html>\n",
            "            \n",
            "Enter your HTML code generation request (or 'exit' to quit): exit\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "class HTMLGenerationModel:\n",
        "    def __init__(self, intents_file):\n",
        "        # Load intents from JSON\n",
        "        with open(intents_file, 'r') as f:\n",
        "            self.intents_data = json.load(f)['intents']\n",
        "\n",
        "        # Prepare training data\n",
        "        self.patterns = []\n",
        "        self.tags = []\n",
        "        self.tag_to_response = {}\n",
        "\n",
        "        # Collect all patterns and tags, and map tags to responses\n",
        "        for intent in self.intents_data:\n",
        "            for pattern in intent['patterns']:\n",
        "                self.patterns.append(pattern.lower())\n",
        "                self.tags.append(intent['tag'])\n",
        "            self.tag_to_response[intent['tag']] = intent['response'][0]\n",
        "\n",
        "        # Tokenization\n",
        "        self.pattern_tokenizer = Tokenizer(oov_token='<OOV>', lower=True)\n",
        "        self.pattern_tokenizer.fit_on_texts(self.patterns)\n",
        "\n",
        "        # Encode tags as integers\n",
        "        self.tag_to_index = {tag: i for i, tag in enumerate(set(self.tags))}\n",
        "        self.index_to_tag = {i: tag for tag, i in self.tag_to_index.items()}\n",
        "\n",
        "        # Vocabulary sizes and input length\n",
        "        self.pattern_vocab_size = len(self.pattern_tokenizer.word_index) + 1\n",
        "        self.max_pattern_length = max([len(pattern.split()) for pattern in self.patterns])\n",
        "        self.num_classes = len(self.tag_to_index)\n",
        "\n",
        "        # Model to be trained\n",
        "        self.model = None\n",
        "\n",
        "    def prepare_data(self):\n",
        "        # Convert patterns to sequences and pad them\n",
        "        pattern_sequences = self.pattern_tokenizer.texts_to_sequences(self.patterns)\n",
        "        padded_patterns = pad_sequences(pattern_sequences, maxlen=self.max_pattern_length, padding='post')\n",
        "\n",
        "        # Convert tags to one-hot labels\n",
        "        tag_indices = [self.tag_to_index[tag] for tag in self.tags]\n",
        "        one_hot_tags = to_categorical(tag_indices, num_classes=self.num_classes)\n",
        "\n",
        "        return padded_patterns, one_hot_tags\n",
        "\n",
        "    def build_model(self):\n",
        "        # Simplified model architecture\n",
        "        model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Embedding(self.pattern_vocab_size, 32, input_length=self.max_pattern_length),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "            tf.keras.layers.Dense(self.num_classes, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def train_model(self):\n",
        "        # Prepare data\n",
        "        X, y = self.prepare_data()\n",
        "\n",
        "        # Split the data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Build and train model\n",
        "        model = self.build_model()\n",
        "\n",
        "        # Train without early stopping to ensure some learning\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=50,\n",
        "            batch_size=16,\n",
        "            validation_split=0.2,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # Evaluate the model\n",
        "        test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "        print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "        self.model = model  # Save the trained model\n",
        "        return model\n",
        "\n",
        "    def predict_response(self, input_texts, confidence_threshold=0.3):\n",
        "        if not self.model:\n",
        "            raise ValueError(\"Model has not been trained. Call train_model() first.\")\n",
        "\n",
        "        if not isinstance(input_texts, list):\n",
        "            input_texts = [input_texts]\n",
        "\n",
        "        responses = []\n",
        "        confidences = []\n",
        "\n",
        "        for input_text in input_texts:\n",
        "            # Preprocess input\n",
        "            input_text = input_text.lower()\n",
        "            input_sequence = self.pattern_tokenizer.texts_to_sequences([input_text])\n",
        "            padded_input = pad_sequences(input_sequence, maxlen=self.max_pattern_length, padding='post')\n",
        "\n",
        "            predictions = self.model.predict(padded_input, verbose=0)\n",
        "            max_confidence = np.max(predictions)\n",
        "            predicted_index = np.argmax(predictions, axis=-1)[0]\n",
        "\n",
        "            if max_confidence < confidence_threshold:\n",
        "                responses.append(None)\n",
        "            else:\n",
        "                predicted_tag = self.index_to_tag[predicted_index]\n",
        "                responses.append(self.tag_to_response.get(predicted_tag, None))\n",
        "\n",
        "            confidences.append(max_confidence)\n",
        "\n",
        "        return responses, confidences\n",
        "\n",
        "\n",
        "class FallbackResponseGenerator:\n",
        "    def __init__(self, intents_file):\n",
        "        # Load intents for more comprehensive fallback\n",
        "        with open(intents_file, 'r') as f:\n",
        "            self.intents_data = json.load(f)['intents']\n",
        "\n",
        "        # Default responses\n",
        "        self.default_responses = [\n",
        "            \"<div>HTML generation not supported</div>\",\n",
        "            \"<p>Unable to generate specific HTML</p>\"\n",
        "        ]\n",
        "\n",
        "    def get_fallback_response(self, query):\n",
        "        # Try to find a response based on keywords\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        for intent in self.intents_data:\n",
        "            for pattern in intent['patterns']:\n",
        "                if pattern.lower() in query_lower:\n",
        "                    return intent['response'][0]\n",
        "\n",
        "        # Return a random default response if no match\n",
        "        return np.random.choice(self.default_responses)\n",
        "\n",
        "\n",
        "def check_language_restriction(user_input):\n",
        "    # List of common programming languages and technologies to restrict\n",
        "    restricted_languages = [\n",
        "        'python', 'java', 'javascript', 'js', 'css', 'php',\n",
        "        'ruby', 'c++', 'c#', 'swift', 'kotlin', 'sql',\n",
        "        'typescript', 'rust', 'golang', 'perl', 'react',\n",
        "        'vue', 'angular', 'node', 'django', 'flask'\n",
        "    ]\n",
        "\n",
        "    user_input = user_input.lower()\n",
        "    return any(lang in user_input for lang in restricted_languages)\n",
        "\n",
        "import re\n",
        "\n",
        "def main():\n",
        "    # Initialize the HTML generation model\n",
        "    intents_file = 'intents.json'\n",
        "    html_model = HTMLGenerationModel(intents_file)\n",
        "\n",
        "    # Train the model\n",
        "    html_model.train_model()\n",
        "\n",
        "    # Initialize fallback generator\n",
        "    fallback_generator = FallbackResponseGenerator(intents_file)\n",
        "\n",
        "    # Interactive loop\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"Enter your HTML code generation request (or 'exit' to quit): \")\n",
        "\n",
        "            if user_input.lower() == 'exit':\n",
        "                break\n",
        "\n",
        "            # Reject non-HTML queries explicitly\n",
        "            if check_language_restriction(user_input):\n",
        "                print(\"This model is designed to generate only HTML code. Please ask for HTML-specific content.\")\n",
        "                continue\n",
        "\n",
        "            # Split the input text based on \"and\" or \",\"\n",
        "            statements = [stmt.strip() for stmt in re.split(r'\\band\\b|,', user_input)]\n",
        "\n",
        "            # Predict the response for each statement\n",
        "            responses, confidences = html_model.predict_response(statements)\n",
        "\n",
        "            # Collect all generated HTML snippets\n",
        "            html_snippets = []\n",
        "            for statement, response, confidence in zip(statements, responses, confidences):\n",
        "                if response:\n",
        "                    html_snippets.append(response)\n",
        "                else:\n",
        "                    # Use fallback generator for unrecognized queries\n",
        "                    fallback_html = fallback_generator.get_fallback_response(statement)\n",
        "                    html_snippets.append(fallback_html)\n",
        "\n",
        "            # Combine all snippets into a complete HTML document\n",
        "            complete_html = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<title>Html generator</title>\n",
        "</head>\n",
        "<body>\n",
        "{}\n",
        "</body>\n",
        "</html>\n",
        "            \"\"\".format(\"\\n\".join(html_snippets))\n",
        "\n",
        "            print(complete_html)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}